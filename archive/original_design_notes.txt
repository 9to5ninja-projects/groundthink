# Original Design Notes

Deep Dive: The Mathematics of RWKV + Mamba Fusion
1. Core Philosophical Differences
RWKV (Recurrent Memory with Fixed Decay)
text
State Update: S_t = S_{t-1} * exp(-w) + k_t * v_t
Where: w is learned constant (per channel)
Philosophy: "Remember everything, but gradually forget"
Behavior: Stable, predictable, good for sequence continuation
Mamba (Selective State Space)
text
State Update: S_t = A_t * S_{t-1} + B_t * x_t
Where: A_t, B_t are input-dependent
Philosophy: "Remember only what matters right now"
Behavior: Dynamic, context-aware, good for reasoning

2. The Hybrid: Selective WKV
The Mathematical Fusion
text
RWKV-Mamba Hybrid State Update:

Let: w_base = learned decay (RWKV grounding)
Let: Δ_t = input-dependent selection (Mamba thinking)
Let: w_hybrid = w_base * sigmoid(linear(x_t))

State Update: S_t = S_{t-1} * exp(-w_hybrid * Δ_t) + (Δ_t * B_t) ⊙ x_t
What This Actually Does:
w_base provides stable temporal structure (prevents catastrophic forgetting)

Δ_t allows the model to "pause decay" when seeing important information

The multiplication w_hybrid * Δ_t creates a dynamic decay rate

3. Behavioral Implications of the Fusion
Token-by-Token Behavior Analysis
text
Scenario 1: Long narrative (storytelling)
Tokens: [Once, upon, a, time, in, a, land, far, far, away...]
RWKV: Decays slowly, maintains all context
Mamba: Might drop "Once" after 100 tokens
Hybrid: Maintains key narrative elements, drops filler words

Scenario 2: Code with function definition
Tokens: [def, calculate, (, x, ), :, \n, return, x, *, 2]
RWKV: Remembers "def calculate" throughout
Mamba: Focuses on current line, might forget function name
Hybrid: Keeps function signature in slow-decay, focuses on body in fast-decay

Scenario 3: Q&A with interrupting context
Tokens: [Q: What is capital of France?][A: Paris][... 1000 tokens ...][Oh wait, I meant in 1800]
RWKV: Still remembers "France" but at reduced strength
Mamba: Might have flushed "France" entirely
Hybrid: Keeps "France" in background (w_base), reactivates it with Δ_t spike

4. The Head-Wise Matrix State Impact
Traditional RWKV (Vector State):
text
S_t ∈ R^{d_model}
Capacity: Single "summary" of entire context
Mamba (Matrix State):
text
S_t ∈ R^{d_state × d_state}
Capacity: Can store multiple "modes" but at same decay rate
Our Hybrid (Head-Wise Matrix):
text
For each head h: S_{t,h} ∈ R^{64×64}
Total: 40 heads × 4096 values = 163,840 state values
Behavioral Impact:

Head 1: Might store "grammatical structure" (slow decay)

Head 2: Might store "topic" (medium decay)

Head 3: Might store "last 3 tokens" (fast decay, high Δ_t sensitivity)

Each head gets its own w_base and Δ_t dynamics

5. The "Communication" Between Mechanisms
Information Flow Analysis:
text
Input x_t → [Projection Layer] → 
    ├── RWKV Pathway: k_t, v_t, r_t, w_base
    └── Mamba Pathway: Δ_t, B_t, C_t
  
Hidden State S_{t-1} → 
    ├── RWKV: Apply decay exp(-w_base)
    └── Mamba: Gate with Δ_t
  
Update: S_t = [RWKV decayed state] + [Mamba gated input]
  
Output: y_t = r_t ⊙ (S_t · C_t + bypass)
Where the Magic Happens:
The w_base * Δ_t interaction creates four behavioral modes:

text
1. Δ_t ≈ 0, w_base normal: "Ignore this token"
2. Δ_t ≈ 1, w_base normal: "Remember briefly"
3. Δ_t ≈ 1, w_base small: "Remember forever"
4. Δ_t large, w_base normal: "Reset/forget previous"

6. Expected Capabilities vs Base Models
Test Cases and Predictions:
python
# Test 1: Long-range dependency
prompt = "The magic word is Xylophone. Remember this." + "..." * 10000 + "What was the magic word?"
# RWKV: ~70% accuracy (decayed but present)
# Mamba: ~30% accuracy (might have flushed)
# Hybrid: ~85% accuracy (kept in slow-decay head)

# Test 2: Logical reasoning
prompt = "If A then B. A is true. Therefore?"
# RWKV: Good at pattern completion
# Mamba: Excellent at logical deduction
# Hybrid: Best of both - remembers premises (RWKV) and applies logic (Mamba)

# Test 3: Context switching
prompt = "Discuss physics." * 100 + "Now discuss poetry."
# RWKV: Slow to switch (carries physics context)
# Mamba: Instant switch (flushes old context)
# Hybrid: Controlled switch (can keep some physics, focus on poetry)
7. Mathematical Stability Analysis
Potential Issues:
Numerical Instability:

RWKV: Stable due to fixed decay

Mamba: Can explode if Δ_t poorly conditioned

Hybrid: Need careful initialization of w_base, Δ_t projections

Training Dynamics:

Two different gradient pathways (RWKV vs Mamba)

Risk of one dominating during training

Need balanced initialization

Inference Consistency:

RWKV: Deterministic output

Mamba: Deterministic but sensitive to Δ_t

Hybrid: More stable than pure Mamba due to w_base anchor

8. The "Grounding vs Thinking" Spectrum Visualization
text
Pure RWKV: |----------G---------------| (all grounding, little thinking)
Pure Mamba: |T-----------------------| (all thinking, little grounding)
Hybrid:     |-----G-----T------| (adaptive mix)

Where at each timestep:
G = 1/(1 + Δ_t)  # Grounding strength (RWKV component)
T = Δ_t/(1 + Δ_t) # Thinking strength (Mamba component)
9. Concrete Example: How It Processes a Sentence
text
Input: "The cat sat on the mat, which was red and fluffy."

Processing steps:
1. "The cat" -> Moderate Δ_t (new entity), stored in head 1
2. "sat" -> Low Δ_t (common verb), minimal update
3. "on the mat" -> High Δ_t (new location), stored in head 2
4. ", which was" -> Low Δ_t (grammatical), passed through
5. "red and fluffy" -> High Δ_t (attributes), linked to "mat" via head 2

Resulting state:
Head 1: ["cat" with medium decay]
Head 2: ["mat" with "red", "fluffy" attributes, slow decay]
Head 3: [current parse state, fast decay]
10. Why This Is Different From Just Stacking Layers
Naive Stacking (RWKV → Mamba):
text
x → RWKV → Mamba → output
Problem: Information loss between layers
Our Fusion (Selective WKV):
text
x → [RWKV + Mamba in same state update] → output
Advantage: Joint optimization of decay and selection
Conclusion on Behavior:
The hybrid will exhibit emergent properties:

Context-aware persistence: Can choose what to remember long-term

Dynamic focus: Can "zoom in" on important details

Stable reasoning: Less likely to hallucinate than pure Mamba

Adaptive forgetting: Better than RWKV at discarding irrelevant context

The key insight: The model learns to allocate different types of information to different heads with different decay-selection profiles, creating a hierarchical memory system within a single layer.
